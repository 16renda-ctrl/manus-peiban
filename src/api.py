import os
import json
import asyncio
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from langgraph.graph import StateGraph
from typing import TypedDict, Literal
from datetime import datetime
from pydantic import BaseModel

# å¯¼å…¥æ ¸å¿ƒå›¾é€»è¾‘
from . import core_graph 

# --- FastAPI Setup ---
app = FastAPI(
    title="Companion Robot Cognitive API",
    description="Real-time WebSocket API for streaming LangGraph execution trace with dynamic configuration.",
)

# å…è®¸è·¨åŸŸè®¿é—®ï¼Œæ–¹ä¾¿å‰ç«¯å¼€å‘
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¼–è¯‘ LangGraph
companion_graph = core_graph.build_companion_graph()
PERSONALITY_MASKS = core_graph.PERSONALITY_MASKS

# --- System Configuration Models ---

class NodeConfig(BaseModel):
    """èŠ‚ç‚¹é…ç½®"""
    id: str
    label: str
    type: str  # "input", "processor", "output"
    angle: float  # åœ†å½¢å¸ƒå±€çš„è§’åº¦

class ConnectionConfig(BaseModel):
    """è¿æ¥é…ç½®"""
    from_node: str
    to_node: str
    color: str  # è¿æ¥çº¿é¢œè‰²

class EmotionConfig(BaseModel):
    """æƒ…ç»ªé…ç½®"""
    name: str
    color: str  # åå…­è¿›åˆ¶é¢œè‰²
    intensity: float  # 0-1 å¼ºåº¦

class SystemConfig(BaseModel):
    """ç³»ç»Ÿé…ç½®"""
    nodes: list[NodeConfig]
    connections: list[ConnectionConfig]
    emotions: list[EmotionConfig]
    personalities: dict[str, dict]

# --- Panel Configuration Models ---

class PanelConfig(BaseModel):
    """é¢æ¿é…ç½®"""
    id: str
    title: str
    type: str  # "status", "metrics", "logs", "memory", "custom"
    icon: str = "ğŸ“Š"
    refreshInterval: int = 1000  # æ¯«ç§’
    description: str = ""

class PanelsConfig(BaseModel):
    """é¢æ¿é›†åˆé…ç½®"""
    panels: list[PanelConfig]
    layout: str = "vertical"
    maxWidth: str = "400px"

# --- System Configuration Endpoint ---

def get_system_config() -> SystemConfig:
    """
    ç”Ÿæˆç³»ç»Ÿé…ç½®ï¼Œå‰ç«¯å¯ä»¥æ ¹æ®æ­¤é…ç½®åŠ¨æ€ç”Ÿæˆç•Œé¢
    è¿™æ ·åç«¯å‡çº§æ—¶ï¼Œå‰ç«¯ä¼šè‡ªåŠ¨é€‚é…
    """
    
    # èŠ‚ç‚¹é…ç½®ï¼ˆä» core_graph ä¸­æå–ï¼‰
    nodes = [
        NodeConfig(id="receive_input", label="æ¥æ”¶è¾“å…¥", type="input", angle=0),
        NodeConfig(id="analyze_emotion", label="æƒ…ç»ªåˆ†æ", type="processor", angle=60),
        NodeConfig(id="decide_skill", label="æŠ€èƒ½å†³ç­–", type="processor", angle=120),
        NodeConfig(id="execute_skill", label="æ‰§è¡ŒæŠ€èƒ½", type="processor", angle=180),
        NodeConfig(id="generate_response", label="ç”Ÿæˆå›å¤", type="processor", angle=240),
        NodeConfig(id="update_history", label="æ›´æ–°å†å²", type="output", angle=300),
    ]
    
    # è¿æ¥é…ç½®
    connections = [
        ConnectionConfig(from_node="receive_input", to_node="analyze_emotion", color="#00BFFF"),
        ConnectionConfig(from_node="analyze_emotion", to_node="decide_skill", color="#00BFFF"),
        ConnectionConfig(from_node="decide_skill", to_node="execute_skill", color="#00BFFF"),
        ConnectionConfig(from_node="execute_skill", to_node="generate_response", color="#9370DB"),
        ConnectionConfig(from_node="generate_response", to_node="update_history", color="#9370DB"),
    ]
    
    # æƒ…ç»ªé…ç½®
    emotions = [
        EmotionConfig(name="happy", color="#FFD700", intensity=1.0),
        EmotionConfig(name="sad", color="#4169E1", intensity=0.8),
        EmotionConfig(name="angry", color="#FF4500", intensity=0.9),
        EmotionConfig(name="neutral", color="#00BFFF", intensity=0.6),
    ]
    
    # äººæ ¼é…ç½®
    personalities = {
        name: {
            "name": config["name"],
            "system_prompt": config["system_prompt"]
        }
        for name, config in PERSONALITY_MASKS.items()
    }
    
    return SystemConfig(
        nodes=nodes,
        connections=connections,
        emotions=emotions,
        personalities=personalities
    )

@app.get("/api/system-config")
async def system_config():
    """
    è¿”å›ç³»ç»Ÿé…ç½®
    å‰ç«¯åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨æ­¤ç«¯ç‚¹ï¼Œè·å–èŠ‚ç‚¹ã€è¿æ¥ã€æƒ…ç»ªç­‰é…ç½®
    """
    config = get_system_config()
    return config.model_dump()

# --- Panels Configuration Endpoint ---

def get_panels_config() -> PanelsConfig:
    """
    ç”Ÿæˆé¢æ¿é…ç½®ï¼Œå‰ç«¯æ ¹æ®æ­¤é…ç½®åŠ¨æ€ç”Ÿæˆä¾§é¢æ¿
    åç«¯å¯ä»¥éšæ—¶æ·»åŠ æ–°é¢æ¿ï¼Œå‰ç«¯ä¼šè‡ªåŠ¨æ˜¾ç¤º
    """
    
    panels = [
        PanelConfig(
            id="llm-status",
            title="LLM è¿æ¥çŠ¶æ€",
            type="status",
            icon="ğŸ”Œ",
            description="æ˜¾ç¤º LLM æœåŠ¡çš„è¿æ¥çŠ¶æ€å’Œå“åº”å»¶è¿Ÿ"
        ),
        PanelConfig(
            id="system-metrics",
            title="ç³»ç»Ÿæ€§èƒ½",
            type="metrics",
            icon="ğŸ“Š",
            description="å®æ—¶ CPUã€å†…å­˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ"
        ),
        PanelConfig(
            id="event-logs",
            title="äº‹ä»¶æ—¥å¿—",
            type="logs",
            icon="ğŸ“",
            description="å®æ—¶ç³»ç»Ÿäº‹ä»¶å’Œé”™è¯¯æ—¥å¿—"
        ),
        PanelConfig(
            id="memory-usage",
            title="å†…å­˜ç®¡ç†",
            type="memory",
            icon="ğŸ’¾",
            description="å¯¹è¯å†å²å’Œç¼“å­˜å†…å­˜ä½¿ç”¨"
        ),
    ]
    
    return PanelsConfig(
        panels=panels,
        layout="vertical",
        maxWidth="400px"
    )

@app.get("/api/panels-config")
async def panels_config():
    """
    è¿”å›é¢æ¿é…ç½®
    å‰ç«¯åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨æ­¤ç«¯ç‚¹ï¼Œè·å–è¦æ˜¾ç¤ºçš„æ‰€æœ‰é¢æ¿
    """
    config = get_panels_config()
    return config.model_dump()

# --- Panel Data Endpoint (for real-time updates) ---

@app.get("/api/panels-data")
async def panels_data():
    """
    è¿”å›æ‰€æœ‰é¢æ¿çš„å®æ—¶æ•°æ®
    å‰ç«¯å¯ä»¥å®šæœŸè°ƒç”¨æ­¤ç«¯ç‚¹è·å–æœ€æ–°æ•°æ®
    """
    import psutil
    
    # LLM çŠ¶æ€
    llm_status = {
        "status": "connected",
        "latency": 45,
    }
    
    # ç³»ç»ŸæŒ‡æ ‡
    system_metrics = {
        "cpu": psutil.cpu_percent(interval=0.1),
        "memory": psutil.virtual_memory().percent,
        "network": 0,  # å¯ä»¥æ‰©å±•ä¸ºå®é™…ç½‘ç»œä½¿ç”¨
    }
    
    # äº‹ä»¶æ—¥å¿—ï¼ˆç¤ºä¾‹ï¼‰
    event_logs = {
        "logs": [
            {"level": "info", "message": "ç³»ç»Ÿå¯åŠ¨å®Œæˆ", "timestamp": "14:30:15"},
            {"level": "info", "message": "WebSocket è¿æ¥å·²å»ºç«‹", "timestamp": "14:30:16"},
        ]
    }
    
    # å†…å­˜ä½¿ç”¨
    memory_usage = {
        "conversationSize": 1024 * 50,  # 50KB
        "cacheSize": 1024 * 100,  # 100KB
    }
    
    return {
        "llm-status": llm_status,
        "system-metrics": system_metrics,
        "event-logs": event_logs,
        "memory-usage": memory_usage,
    }

# --- WebSocket Endpoint ---

@app.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("WebSocket connected")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    current_state = {
        "conversation_history": [],
        "current_personality": "mentor",
    }

    try:
        while True:
            # 1. æ¥æ”¶ç”¨æˆ·è¾“å…¥å’Œäººæ ¼é€‰æ‹©
            data = await websocket.receive_text()
            message = json.loads(data)
            
            user_input = message.get("user_input", "").strip()
            personality = message.get("personality", "mentor").strip().lower()
            
            if not user_input:
                continue

            # æ›´æ–°å½“å‰äººæ ¼
            current_state["current_personality"] = personality
            
            # å‡†å¤‡å›¾çš„è¾“å…¥çŠ¶æ€
            input_state = core_graph.CompanionState(
                user_input=user_input,
                current_personality=personality,
                conversation_history=current_state["conversation_history"],
                detected_emotion="",
                should_use_skill=False,
                skill_to_use="",
                skill_result="",
                final_response="",
            )

            # 2. å‘é€å¼€å§‹ä¿¡å·ï¼ˆè‡ªæè¿°äº‹ä»¶ï¼‰
            await websocket.send_json({
                "type": "start",
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "input": user_input,
                    "personality": personality,
                }
            })

            # 3. å®æ—¶æµå¼ä¼ è¾“ LangGraph æ‰§è¡Œè½¨è¿¹
            full_response_buffer = ""
            
            # ä½¿ç”¨ astream å®æ—¶è·å–æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º
            async for step in companion_graph.astream(input_state):
                node_name = list(step.keys())[0]
                state_update = step[node_name]
                
                # å‘é€è‡ªæè¿°çš„èŠ‚ç‚¹æ‰§è¡Œäº‹ä»¶
                event_data = {
                    "type": "node_executed",
                    "timestamp": datetime.now().isoformat(),
                    "metadata": {
                        "node_id": node_name,
                        "state_update": str(state_update)[:100],  # é™åˆ¶å¤§å°
                    }
                }
                
                # ç‰¹æ®Šå¤„ç†æƒ…ç»ªæ£€æµ‹
                if "detected_emotion" in state_update:
                    event_data["metadata"]["emotion"] = state_update["detected_emotion"]
                
                # ç‰¹æ®Šå¤„ç†æœ€ç»ˆå›å¤
                if "final_response" in state_update:
                    full_response_buffer = state_update["final_response"]
                    event_data["metadata"]["response_preview"] = full_response_buffer[:50]
                
                await websocket.send_json(event_data)

            # 4. å‘é€å®Œæ•´å›å¤
            await websocket.send_json({
                "type": "response_complete",
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "response": full_response_buffer,
                }
            })
            
            # 5. æ›´æ–°å†å²è®°å½•
            current_state["conversation_history"].append({
                "user": user_input,
                "bot": full_response_buffer
            })

            # 6. å‘é€ç»“æŸä¿¡å·
            await websocket.send_json({
                "type": "end",
                "timestamp": datetime.now().isoformat(),
                "metadata": {}
            })

    except WebSocketDisconnect:
        print("WebSocket disconnected")
    except Exception as e:
        print(f"Error: {e}")
        try:
            await websocket.send_json({
                "type": "error",
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "message": str(e)
                }
            })
        except:
            pass

# --- Uvicorn å¯åŠ¨é…ç½® ---
if __name__ == "__main__":
    import uvicorn
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    os.chdir(project_root)
    uvicorn.run(app, host="0.0.0.0", port=8000)
